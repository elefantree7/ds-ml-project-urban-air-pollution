{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f85a71b",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "steps:\n",
    "- Preprocessing the test set like the train data\n",
    "- Scaling the data (test and train)\n",
    "- function for model_evaluation\n",
    "- function for model building\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c01a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd664c90",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f543dc",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36832228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05ddec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop('target', axis=1)\n",
    "y_train = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45dcd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4dd0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel\n",
    "# testing of different models\n",
    "\n",
    "# root mean squared error\n",
    "# r^2\n",
    "\n",
    "\n",
    "def model_evaluation(clf, X_train, y_train, scoring=(r2_score, mean_squared_error)):\n",
    "\n",
    "    results = {}\n",
    "    scores = cross_validate(clf, X_train, y_train, scoring=scoring, cv=5, n_jobs=-1)\n",
    "    results = {key: [value.mean().round(4), value.std().round(4)] for key, value in scores.items()}\n",
    "\n",
    "    #del results['fit_time']\n",
    "    #del results['score_time']\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "146dcc60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 22917]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m list_of_clf = [LinearRegression(), KNeighborsClassifier(), RandomForestClassifier(random_state=RSEED)]\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m list_of_clf:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     results = \u001b[43mmodel_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mr2_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_squared_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(clf)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mR^2 (mean, std): \u001b[39m\u001b[33m'\u001b[39m, results[\u001b[33m\"\u001b[39m\u001b[33mtest_r2\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mmodel_evaluation\u001b[39m\u001b[34m(clf, X_train, y_train, scoring)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_evaluation\u001b[39m(clf, X_train, y_train, scoring=(r2_score, mean_squared_error)):\n\u001b[32m     10\u001b[39m     results = {}\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     scores = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     results = {key: [value.mean().round(\u001b[32m4\u001b[39m), value.std().round(\u001b[32m4\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m scores.items()}\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m#del results['fit_time']\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m#del results['score_time']\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\konst\\Documents\\Katja\\Data_science\\Repos\\ds-ml-project-urban-air-pollution\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:252\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcross_validate\u001b[39m(\n\u001b[32m     50\u001b[39m     estimator,\n\u001b[32m     51\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m     error_score=np.nan,\n\u001b[32m     64\u001b[39m ):\n\u001b[32m     65\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[32m     66\u001b[39m \n\u001b[32m     67\u001b[39m \u001b[33;03m    Read more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m \u001b[33;03m    [0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     X, y, groups = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m     cv = check_cv(cv, y, classifier=is_classifier(estimator))\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\konst\\Documents\\Katja\\Data_science\\Repos\\ds-ml-project-urban-air-pollution\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    425\u001b[39m \n\u001b[32m    426\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    439\u001b[39m \u001b[33;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[32m    440\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    442\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\konst\\Documents\\Katja\\Data_science\\Repos\\ds-ml-project-urban-air-pollution\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    395\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    398\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    399\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    400\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [2, 22917]"
     ]
    }
   ],
   "source": [
    "# Beispiel\n",
    "list_of_clf = [LinearRegression(), KNeighborsClassifier(), RandomForestClassifier(random_state=RSEED)]\n",
    "\n",
    "for clf in list_of_clf:\n",
    "    results = model_evaluation(clf, (r2_score, mean_squared_error), X_train, y_train)\n",
    "    print(clf)\n",
    "    print('R^2 (mean, std): ', results[\"test_r2\"])\n",
    "    print('RMSE (mean, std): ', -results[\"test_neg_mean_squared_error\"])\n",
    "    print('----'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6214a",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "- LinearRegression - GradientDescent\n",
    "- KNN - GridSearchCV?\n",
    "- Decision Tree - GridSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef81879",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7968e8b",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
